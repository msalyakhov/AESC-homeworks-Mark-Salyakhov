{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72bc483c",
   "metadata": {},
   "source": [
    "# Кластеризация ЕГЭ (4 если сделаны все задачи)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bc2fba",
   "metadata": {},
   "source": [
    "Рядом лежат данные с координатами точек. Везде используется Евклидово расстояние. Кластером считается набор не менее чем из 30 точек связанных друг с другом. Аномалия это точка находящаяся на расстоянии более 1 от любого кластера.\n",
    "\n",
    "* Постройте Распределение точек\n",
    "* Напишите руками DBSCAN и обработайте им все файлы\n",
    "* Файл 0.xls также решите руками\n",
    "* Постройте Распределение точек, отметьте принадлежность кластеров цветами\n",
    "* Отметьте Аномалии отдельным цветом\n",
    "* Найдите среди в каждом кластере точку расстояние от которой до всех остальных минимально\n",
    "* Выведите два числа - Среднее абсцисс и ординат центроидов кластеров * 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6a6519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "names = [\"0.xls\", \"1.xls\", \"2.txt\", \"3.txt\", \"4.txt\", \"5.txt\"]\n",
    "\n",
    "PARAMS = {\n",
    "    \"0.xls\": (0.55, 5),\n",
    "    \"1.xls\": (0.45, 40),\n",
    "    \"2.txt\": (0.65, 10),\n",
    "    \"3.txt\": (0.60, 30),\n",
    "    \"4.txt\": (0.50, 10),\n",
    "    \"5.txt\": (0.55, 50),\n",
    "}\n",
    "\n",
    "for name in names:\n",
    "    df = pd.read_excel(name) if name.endswith(\".xls\") else pd.read_csv(name)\n",
    "\n",
    "    x = df[\"X\"].to_numpy(dtype=np.float32, copy=False)\n",
    "    y = df[\"Y\"].to_numpy(dtype=np.float32, copy=False)\n",
    "    XY = np.column_stack([x, y]).astype(np.float32, copy=False)\n",
    "\n",
    "    eps, min_samples = PARAMS[name]\n",
    "\n",
    "    D = cdist(XY, XY).astype(np.float32, copy=False)\n",
    "    neigh = D <= np.float32(eps)\n",
    "\n",
    "    n = XY.shape[0]\n",
    "    labels = np.full(n, -2, dtype=np.int32)\n",
    "    visited = np.zeros(n, dtype=bool)\n",
    "    cid = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        if visited[i]:\n",
    "            continue\n",
    "        visited[i] = True\n",
    "        Ni = np.flatnonzero(neigh[i])\n",
    "        if Ni.size < min_samples:\n",
    "            labels[i] = -1\n",
    "            continue\n",
    "        labels[i] = cid\n",
    "        q = list(Ni)\n",
    "        while q:\n",
    "            j = q.pop()\n",
    "            if not visited[j]:\n",
    "                visited[j] = True\n",
    "                Nj = np.flatnonzero(neigh[j])\n",
    "                if Nj.size >= min_samples:\n",
    "                    q.extend(Nj.tolist())\n",
    "            if labels[j] in (-2, -1):\n",
    "                labels[j] = cid\n",
    "        cid += 1\n",
    "\n",
    "    clusters = np.unique(labels)\n",
    "    clusters = clusters[clusters != -1]\n",
    "\n",
    "    centroids = []\n",
    "    medoids = []\n",
    "\n",
    "    for k in clusters:\n",
    "        idx = np.flatnonzero(labels == k)\n",
    "        P = XY[idx]\n",
    "        centroids.append(P.mean(axis=0))\n",
    "        d = cdist(P, P)\n",
    "        medoids.append(idx[int(np.argmin(d.sum(axis=1)))])\n",
    "\n",
    "    centroids = np.array(centroids, dtype=np.float64)\n",
    "    if centroids.size:\n",
    "        mx, my = (centroids.mean(axis=0) * 100000.0)\n",
    "        print(name, mx, my)\n",
    "    else:\n",
    "        print(name, \"no_clusters\")\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    noise = labels == -1\n",
    "    plt.scatter(x[noise], y[noise], s=6, c=\"k\", alpha=0.7)\n",
    "\n",
    "    cmap = plt.get_cmap(\"tab20\")\n",
    "    for t, k in enumerate(clusters):\n",
    "        m = labels == k\n",
    "        plt.scatter(x[m], y[m], s=6, color=cmap(t % 20), alpha=0.85)\n",
    "\n",
    "    if medoids:\n",
    "        mi = np.array(medoids, dtype=np.int32)\n",
    "        plt.scatter(x[mi], y[mi], marker=\"x\", s=60, color=\"red\")\n",
    "\n",
    "    plt.title(name)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3df8814",
   "metadata": {},
   "source": [
    "# Кластеризация (1 за каждый алгоритм на всех данных)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf53319",
   "metadata": {},
   "source": [
    "На предложенных распределениях данных проверьте предложенные алгоритмы. Постройте графики кластеризации для каждой пары алгоритм-данные, разные кластеры покрасьте разным цветом. Воспользуйтесь sklearn реализациями. Параметры кластеризации для разных алгоритмов подберите такие, чтобы алгоритмы можно было сравнивать (по возможности одинаковое количество кластеров и т.д.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e323b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import cycle, islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f18470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_means =  \n",
    "dbscan = \n",
    "\n",
    "clustering_algorithms = (\n",
    "        (\"MeanShift\", ms),\n",
    "        (\"Spectral\\nClustering\", spectral),\n",
    "        (\"Ward\", ward),\n",
    "        (\"Agglomerative\\nClustering\", average_linkage),\n",
    "        (\"OPTICS\", optics),\n",
    "        (\"Gaussian\\nMixture\", gmm),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae73f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# ============\n",
    "# Generate datasets. We choose the size big enough to see the scalability\n",
    "# of the algorithms, but not too big to avoid too long running times\n",
    "# ============\n",
    "n_samples = 1500\n",
    "noisy_circles = datasets.make_circles(n_samples=n_samples, factor=0.5, noise=0.05)\n",
    "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=0.05)\n",
    "blobs = datasets.make_blobs(n_samples=n_samples, random_state=8)\n",
    "no_structure = np.random.rand(n_samples, 2), None\n",
    "\n",
    "# Anisotropicly distributed data\n",
    "random_state = 170\n",
    "X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
    "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "X_aniso = np.dot(X, transformation)\n",
    "aniso = (X_aniso, y)\n",
    "\n",
    "# blobs with varied variances\n",
    "varied = datasets.make_blobs(\n",
    "    n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=random_state\n",
    ")\n",
    "\n",
    "# ============\n",
    "# Set up cluster parameters\n",
    "# ============\n",
    "plt.figure(figsize=(9 * 2 + 3, 13))\n",
    "plt.subplots_adjust(\n",
    "    left=0.02, right=0.98, bottom=0.001, top=0.95, wspace=0.05, hspace=0.01\n",
    ")\n",
    "\n",
    "plot_num = 1\n",
    "\n",
    "default_base = {\n",
    "    \"quantile\": 0.3,\n",
    "    \"eps\": 0.3,\n",
    "    \"damping\": 0.9,\n",
    "    \"preference\": -200,\n",
    "    \"n_neighbors\": 10,\n",
    "    \"n_clusters\": 3,\n",
    "    \"min_samples\": 20,\n",
    "    \"xi\": 0.05,\n",
    "    \"min_cluster_size\": 0.1,\n",
    "}\n",
    "\n",
    "datasets = [\n",
    "    (\n",
    "        noisy_circles,\n",
    "        {\n",
    "            \"damping\": 0.77,\n",
    "            \"preference\": -240,\n",
    "            \"quantile\": 0.2,\n",
    "            \"n_clusters\": 2,\n",
    "            \"min_samples\": 20,\n",
    "            \"xi\": 0.25,\n",
    "        },\n",
    "    ),\n",
    "    (noisy_moons, {\"damping\": 0.75, \"preference\": -220, \"n_clusters\": 2}),\n",
    "    (\n",
    "        varied,\n",
    "        {\n",
    "            \"eps\": 0.18,\n",
    "            \"n_neighbors\": 2,\n",
    "            \"min_samples\": 5,\n",
    "            \"xi\": 0.035,\n",
    "            \"min_cluster_size\": 0.2,\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        aniso,\n",
    "        {\n",
    "            \"eps\": 0.15,\n",
    "            \"n_neighbors\": 2,\n",
    "            \"min_samples\": 20,\n",
    "            \"xi\": 0.1,\n",
    "            \"min_cluster_size\": 0.2,\n",
    "        },\n",
    "    ),\n",
    "    (blobs, {}),\n",
    "    (no_structure, {}),\n",
    "]\n",
    "\n",
    "for i_dataset, (dataset, algo_params) in enumerate(datasets):\n",
    "    # update parameters with dataset-specific values\n",
    "    params = default_base.copy()\n",
    "    params.update(algo_params)\n",
    "\n",
    "    X, y = dataset\n",
    "\n",
    "    # normalize dataset for easier parameter selection\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # estimate bandwidth for mean shift\n",
    "    bandwidth = cluster.estimate_bandwidth(X, quantile=params[\"quantile\"])\n",
    "\n",
    "    # connectivity matrix for structured Ward\n",
    "    connectivity = kneighbors_graph(\n",
    "        X, n_neighbors=params[\"n_neighbors\"], include_self=False\n",
    "    )\n",
    "    # make connectivity symmetric\n",
    "    connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "    for name, algorithm in clustering_algorithms:\n",
    "        t0 = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
